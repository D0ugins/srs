{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19824806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATA_PATH=../../../data\n",
    "from db import *\n",
    "from sqlalchemy import insert, select\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from lib.fit import load_fit_file, FIT_EPOCH_S, get_camera_ends, get_camera_starts, get_gps_data\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "DATA_PATH = '../../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952e47e",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08765a57",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65014f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT_PATH = f\"{DATA_PATH}/virbs/all\"\n",
    "VID_PATH = f\"{DATA_PATH}/videos/previews\"\n",
    "fit_files = [p.split('/')[-1] for p in glob.glob(f\"{FIT_PATH}/*.fit\")]\n",
    "vid_files = [p.split('/')[-1] for p in glob.glob(f\"{VID_PATH}/*.MP4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTS_PATH = '/mnt/c/Users/yusuf/AppData/Roaming/Garmin/VIRB Edit/Database/7/MovieProjects'\n",
    "RAW_MOVIE_PATH = \"/mnt/c/Users/yusuf/AppData/Roaming/Garmin/VIRB Edit/Database/7/RawMovies\"\n",
    "\n",
    "project_files = ['/'.join(p.split('/')[-2:]) for p in glob.glob(f\"{PROJECTS_PATH}/*/edited_movie.xml\")]\n",
    "raw_movie_files = ['/'.join(p.split('/')[-2:])for p in glob.glob(f\"{RAW_MOVIE_PATH}/*/video.xml\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b736ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_movies = {}\n",
    "for f in raw_movie_files:\n",
    "    root = ET.parse(f\"{RAW_MOVIE_PATH}/{f}\").getroot()\n",
    "    fit = root.find('./TelemetryTypeAssociations/TelemetryTypeAssociation_t/SourceFilePath').text\n",
    "    preview = root.find('./SourceFiles/MediaSourceFile_t/LowResolutionFilePath').text.split('\\\\')[-1]\n",
    "    if preview == \"7de890f8-fb7a-49aa-97a7-96eaf53a7a44.MP4\": # TODO: script to split large video files from broken rolls\n",
    "        print(\"Skipping known double video\")\n",
    "    raw_movies[f.split('/')[0]] = dict(fit=fit, preview=preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for f in project_files:\n",
    "    root = ET.parse(f\"{PROJECTS_PATH}/{f}\").getroot()\n",
    "    raw_movie_id = root.find('./VideoClips/VideoClip_t/RawMovies/RawMovieDisplay_t/RawMovieId').text\n",
    "    name = root.find('Name').text\n",
    "    \n",
    "    if raw_movie_id not in raw_movies:\n",
    "        print(f\"Skipping {name}, raw movie id {raw_movie_id} not found\")\n",
    "        continue\n",
    "   \n",
    "    files.append(dict(\n",
    "        name=name,\n",
    "        project_id=f.split('/')[0],\n",
    "        raw_movie_id=raw_movie_id,\n",
    "        fit_file=raw_movies[raw_movie_id]['fit'],\n",
    "        preview_file=raw_movies[raw_movie_id]['preview']\n",
    "    ))\n",
    "files = sorted(files, key=lambda x: x['name'])\n",
    "with open(\"../../../tmp/ids.json\", \"w\") as f:\n",
    "    json.dump(files, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1034765",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30714be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    sensor, fit_file = file['fit_file'].split('/')\n",
    "    year, month, day, hour, minute, second = fit_file.split('.')[0].split('-')\n",
    "    start_time = f\"{year}-{month}-{day}T{hour}:{minute}:{second}Z\"\n",
    "    parts = file['name'].split('_')\n",
    "    date = '_'.join(parts[:3])\n",
    "    driver = parts[3]\n",
    "    buggy = parts[4]\n",
    "    vid_type = \"video_preview_c\" if parts[-1] == \"crotch\" else \"video_preview\"\n",
    "    if parts[-1] == \"crotch\":\n",
    "        parts = parts[:-1]\n",
    "    num = parts[-1]\n",
    "    return dict(\n",
    "        driver=driver,\n",
    "        buggy=buggy,\n",
    "        date=date,\n",
    "        start_time=start_time, num=num,\n",
    "        vid_type=vid_type,\n",
    "        preview=file['preview_file'],\n",
    "        fit_file=fit_file,\n",
    "        sensor=sensor\n",
    "    )\n",
    "file_data = [get_data(f) for f in files]\n",
    "file_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(\n",
    "    sensors = set([fd['sensor'] for fd in file_data]),\n",
    "    dates= set([fd['date'] for fd in file_data]),\n",
    "    drivers= set([fd['driver'] for fd in file_data]),\n",
    "    buggies= set([fd['buggy'] for fd in file_data]),\n",
    "    vid_types= set([fd['vid_type'] for fd in file_data]),\n",
    "    nums= set([fd['num'] for fd in file_data])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = {\n",
    "    3937722707: 'zr',\n",
    "    3309634073: 'sr',\n",
    "    3309634073: 'kpf',\n",
    "    3309634073: 'ir'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d29e3",
   "metadata": {},
   "source": [
    "# DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(engine)\n",
    "driver_map = {\n",
    "    'Alani': Driver(name='Alani'),\n",
    "    'Audrey': Driver(name='Audrey'),\n",
    "    'Cadence': Driver(name='Cadence'),\n",
    "    'Daisy': Driver(name='Daisy'),\n",
    "    'Meixi': Driver(name=\"Mei Xi\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_map = {\n",
    "    'Inviscid': Buggy(name='Inviscid', abbreviation='inviscid'),\n",
    "    'KP': Buggy(name='Kingping II', abbreviation='kp'),\n",
    "    'Seraph': Buggy(name='Seraph', abbreviation='seraph'),\n",
    "    'Zuke': Buggy(name='Zuke', abbreviation='zuke'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_map = {\n",
    "  '2025_09_20': RollDate(year=2025, month=9, day=20, type=RollType.WEEKEND),\n",
    "  '2025_09_21': RollDate(year=2025, month=9, day=21, type=RollType.WEEKEND),\n",
    "  '2025_09_27': RollDate(year=2025, month=9, day=27, type=RollType.WEEKEND),\n",
    "  '2025_11_02': RollDate(year=2025, month=11, day=2, type=RollType.WEEKEND),\n",
    "  '2025_11_08': RollDate(year=2025, month=11, day=8, type=RollType.WEEKEND),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_map = {\n",
    "  '3309634073': Sensor(type=\"virb\", name=\"Inviscid R\", abbreviation=\"3309634073\"),\n",
    "  '3937722707': Sensor(type=\"virb\", name=\"Zuke R\", abbreviation=\"3937722707\"),\n",
    "  '3953097982': Sensor(type=\"virb\", name=\"Kingpin F\", abbreviation=\"3953097982\"),\n",
    "  '3957747616': Sensor(type=\"virb\", name=\"Seraph R\", abbreviation=\"3957747616\"),\n",
    "  '3993910820': Sensor(type=\"virb\", name=\"Unknown Virb 1\", abbreviation=\"3993910820\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc76cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_all(driver_map.values())\n",
    "session.add_all(buggy_map.values())\n",
    "session.add_all(dates_map.values())\n",
    "session.add_all(sensor_map.values())\n",
    "session.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f740cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = {}\n",
    "fit_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roll(file):\n",
    "    driver = driver_map[file['driver']]\n",
    "    buggy = buggy_map[file['buggy']]\n",
    "    date = dates_map[file['date']]\n",
    "    num = int(file['num'])\n",
    "    start_time = datetime.fromisoformat(file['start_time'])\n",
    "    key = (buggy.id, date.id, num)\n",
    "    if key in rolls:\n",
    "        print(f\"Duplicate roll for {file['fit_file']} {key}\")\n",
    "        roll = rolls[key]\n",
    "    else:\n",
    "        roll = Roll(driver=driver, buggy=buggy, roll_date=date, roll_number=num, start_time=start_time)\n",
    "        rolls[key] = roll\n",
    "        \n",
    "    sensor = sensor_map[file['sensor']]\n",
    "    roll.roll_files.append(\n",
    "        RollFile(type=file['vid_type'], uri=f\"%videos%/previews/{file['preview']}\", sensor=sensor)\n",
    "    )\n",
    "    roll.roll_files.append(\n",
    "        RollFile(type=\"fit\", uri=f\"%fit%/all/{file['fit_file']}\", sensor=sensor)\n",
    "    )\n",
    "    \n",
    "    session.add(roll)\n",
    "    session.add_all(roll.roll_files)\n",
    "    rolls[key] = roll\n",
    "    return roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_data:\n",
    "    add_roll(file)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e293",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479458b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "hills = gpd.read_file(f\"{DATA_PATH}/geo/hills.kml\", crs=\"EPSG:4326\")\n",
    "hills_utm = hills.to_crs(hills.estimate_utm_crs())\n",
    "hill1, hill2, freeroll, hill3, hill4, hill5, _end = shapely.force_2d(hills.iloc[0].geometry).geoms\n",
    "hill1_utm, hill2_utm, freeroll_utm, hill3_utm, hill4_utm, hill5_utm, end_utm = shapely.force_2d(hills_utm.iloc[0].geometry).geoms\n",
    "end_offset = shapely.force_2d(gpd.read_file(f\"{DATA_PATH}/geo/end_offset.kml\").iloc[0].geometry)\n",
    "freeroll_point = shapely.force_2d(gpd.read_file(f\"{DATA_PATH}/geo/freeroll_point.kml\").iloc[0].geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roll_events(fit_file):\n",
    "    roll = session.get(Roll, fit_file.roll_id)\n",
    "    if not roll: raise ValueError(f\"Roll not found for roll file id {fit_file.roll_id}\")\n",
    "    \n",
    "    messages = load_fit_file(fit_file.uri.replace('%fit%', \"virbs\"))\n",
    "    camera_starts = get_camera_starts(messages)\n",
    "    if len(camera_starts) != 1:\n",
    "        print(f\"Skipping {fit_file} with {len(camera_starts)} camera starts\")\n",
    "        return \n",
    "    \n",
    "    gps_data = get_gps_data(messages)\n",
    "    if gps_data is None:\n",
    "        print(f\"Skipping {fit_file} with no gps_data\")\n",
    "        return\n",
    "    gps_data['speed'] = np.linalg.norm(np.array(gps_data.velocity.to_list()), axis=1)\n",
    "    \n",
    "    # set up roll points\n",
    "    roll_points = shapely.points(gps_data[['position_long', 'position_lat']])\n",
    "    point_utm = gpd.GeoSeries(roll_points, index=gps_data.index, crs=\"EPSG:4326\")\n",
    "    point_utm = point_utm.to_crs(point_utm.estimate_utm_crs()) # converts to coordinate systems where distances are nice\n",
    "    roll_point_timestamp = {p: gps_data.index[i] for i, p in enumerate(roll_points)} # type: ignore\n",
    "    \n",
    "    # look at a point in the middle of the freeroll, then find soonest time stopped before that as start of roll\n",
    "    roll_point_in_freeroll, _ = nearest_points(shapely.union_all(roll_points), freeroll_point)\n",
    "    before_points = gps_data.loc[:roll_point_timestamp[roll_point_in_freeroll]]\n",
    "    pre_start_points = before_points[before_points.speed < 0.5]\n",
    "    roll_start = gps_data.index[0] if len(pre_start_points) < 10 else pre_start_points.timestamp.iloc[-10] # default to start of roll\n",
    "    \n",
    "    # buggy might stop at end, so look at a point 10 meters before end and extrapolate time from speed there\n",
    "    roll_points = shapely.points(gps_data[['position_long', 'position_lat']].loc[roll_start:])\n",
    "    roll_end_offset_point, _ = nearest_points(shapely.union_all(roll_points), end_offset)\n",
    "    roll_end_offset = roll_point_timestamp[roll_end_offset_point]\n",
    "    if gps_data.speed.loc[roll_end_offset] < 0.1:\n",
    "        roll_end = gps_data.index[-1]\n",
    "    else:\n",
    "        roll_end = roll_end_offset + 1000 * (10 / gps_data.speed.loc[roll_end_offset])\n",
    "        roll_end = gps_data.index[gps_data.index.get_indexer([roll_end], method='nearest')[0]] # type: ignore\n",
    "\n",
    "    roll_points = shapely.points(gps_data[['position_long', 'position_lat']].loc[roll_start:roll_end])\n",
    "    roll_line = shapely.union_all(roll_points)\n",
    "    \n",
    "    # get nearest points to hill lines\n",
    "    hill1_point, _ = nearest_points(roll_line, hill1)\n",
    "    hill2_point, _ = nearest_points(roll_line, hill2)\n",
    "    freeroll_point_on_roll, _ = nearest_points(roll_line, freeroll)\n",
    "    hill3_point, _ = nearest_points(roll_line, hill3)\n",
    "    hill4_point, _ = nearest_points(roll_line, hill4)\n",
    "    hill5_point, _ = nearest_points(roll_line, hill5)\n",
    "    \n",
    "    # get timestamps\n",
    "    hill1_start = roll_point_timestamp[hill1_point]\n",
    "    hill2_start = roll_point_timestamp[hill2_point]\n",
    "    freeroll_start = roll_point_timestamp[freeroll_point_on_roll]\n",
    "    hill3_start = roll_point_timestamp[hill3_point]\n",
    "    hill4_start = roll_point_timestamp[hill4_point]\n",
    "    hill5_start = roll_point_timestamp[hill5_point]\n",
    "    \n",
    "    \n",
    "    roll.roll_events.append(RollEvent(type=\"roll_start\", timestamp_ms=roll_start))\n",
    "    \n",
    "    # Distances in meters because of utm coordinate system\n",
    "    # if the start was close to hill1, make hill 1 start that\n",
    "    if roll_start != gps_data.index[0] and shapely.distance(point_utm.loc[roll_start], hill1_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"1\", timestamp_ms=roll_start))\n",
    "    elif shapely.distance(point_utm.loc[hill1_start], hill1_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"1\", timestamp_ms=hill1_start))     \n",
    "    # if start was close to hill 2, make hill 2 start that\n",
    "    if roll_start != gps_data.index[0] and shapely.distance(point_utm.loc[roll_start], hill2_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"2\", timestamp_ms=roll_start))\n",
    "    elif shapely.distance(point_utm.loc[hill2_start], hill2_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"2\", timestamp_ms=hill2_start))\n",
    "    # include starts if close\n",
    "    if shapely.distance(point_utm.loc[freeroll_start], freeroll_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"freeroll_start\", timestamp_ms=freeroll_start))\n",
    "    if shapely.distance(point_utm.loc[hill3_start], hill3_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"3\", timestamp_ms=hill3_start))\n",
    "    if shapely.distance(point_utm.loc[hill4_start], hill4_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"4\", timestamp_ms=hill4_start))\n",
    "    if shapely.distance(point_utm.loc[hill5_start], hill5_utm) < 10:\n",
    "        roll.roll_events.append(RollEvent(type=\"hill_start\", tag=\"5\", timestamp_ms=hill5_start))\n",
    "    \n",
    "    \n",
    "    roll.roll_events.append(RollEvent(type=\"roll_end\", timestamp_ms=roll_end))\n",
    "    # events at very start or end are probably wrong\n",
    "    roll.roll_events = [e for e in roll.roll_events if gps_data.index[0] < e.timestamp_ms < gps_data.index[-1]]\n",
    "    for e in roll.roll_events: e.timestamp_ms = int(e.timestamp_ms)\n",
    "    print(roll.roll_events)\n",
    "    session.add_all(roll.roll_events)\n",
    "    # print(fit_file, roll.roll_events)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef018be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_files = session.execute(select(RollFile).where(RollFile.type == \"fit\")).scalars().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60daed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for fit_file in tqdm(fit_files):\n",
    "        add_roll_events(fit_file)\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise e\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020f11d",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('./data/ir_11_2/medialist.json') as f:\n",
    "    media_list = json.load(f)['media'][4:]\n",
    "media_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for media in tqdm(media_list):\n",
    "    url = media['lowResVideoPath']\n",
    "    # Stream video to file\n",
    "    response = requests.get(url)\n",
    "    filename = url.split('/')[-1].replace('GLV', 'mp4')\n",
    "    with open(f'../../../videos/ir_11_2/{filename}', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1eaed8",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867c573",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = raw_movie_files[0]\n",
    "def fix_path(p):\n",
    "    return p.replace('C:', '/mnt/c').replace('\\\\', '/')\n",
    "ET.parse(f\"{RAW_MOVIE_PATH}/{tmp}\").getroot().find('./TelemetryTypeAssociations/TelemetryTypeAssociation_t/SourceFilePath').text\n",
    "fix_path(ET.parse(f\"{RAW_MOVIE_PATH}/{tmp}\").getroot().find('./SourceFiles/MediaSourceFile_t/LowResolutionFilePath').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29218917",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = project_files[0]\n",
    "\n",
    "ET.parse(f\"{PROJECTS_PATH}/{tmp}\").getroot().find('Name').text\n",
    "ET.parse(f\"{PROJECTS_PATH}/{tmp}\").getroot().find('./VideoClips/VideoClip_t/RawMovies/RawMovieDisplay_t/RawMovieId').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1791b5",
   "metadata": {},
   "source": [
    "### Extract times\n",
    "(not needed if above works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_objs = {}\n",
    "for fit_file in tqdm(fit_files):\n",
    "    message_objs[fit_file] = load_fit_file(f\"{FIT_PATH}/{fit_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_times_list = []\n",
    "for fit_file, messages in message_objs.items():\n",
    "    ends = get_camera_ends(messages)\n",
    "    if (len(ends) != 1): \n",
    "        print(f\"Skipping {fit_file} with {len(ends)} camera ends\")\n",
    "        continue\n",
    "    starts = get_camera_starts(messages)\n",
    "    creation_time = messages['file_id_mesgs'][0]['time_created'] + FIT_EPOCH_S # + ends[0] // 1000\n",
    "    creation_times_list.append((fit_file, creation_time))\n",
    "creation_times = dict(sorted(creation_times_list, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{k: datetime.fromtimestamp(v).strftime('%Y-%m-%dT:%H:%M:%SZ') for k, v in creation_times.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "[datetime.fromtimestamp(v).strftime('%Y-%m-%dT:%H:%M:%SZ') for v in creation_times.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc23582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract creation time from each video file\n",
    "# import ffmpeg\n",
    "# vid_creation_times_list = []\n",
    "# for vid_file in tqdm(vid_files):\n",
    "#     try:\n",
    "#         probe = ffmpeg.probe(f'{VID_PATH}/{vid_file}')\n",
    "#         creation_time = probe.get('format', {}).get('tags', {}).get('creation_time')\n",
    "#         vid_creation_times_list.append((vid_file, creation_time))\n",
    "#     except ffmpeg.Error as e:\n",
    "#         vid_creation_times_list.append((vid_file, None))\n",
    "#         print(f\"Error probing {vid_file}: {e}\")\n",
    "\n",
    "# vid_creation_times = dict(sorted(vid_creation_times_list, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(vid_creation_times.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a693a32",
   "metadata": {},
   "source": [
    "## Load from medialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_roll(session: Session, media: dict, \n",
    "             roll_date: RollDate, driver: Driver, buggy: Buggy, sensor: Sensor, \n",
    "             roll_num: int, use_thm: bool = False):\n",
    "    dt = datetime.fromtimestamp(media['date'])\n",
    "    roll = Roll(roll_date_id=roll_date.id, \n",
    "                driver_id=driver.id,\n",
    "                buggy_id=buggy.id,\n",
    "                roll_number=roll_num,\n",
    "                start_time=dt)\n",
    "    session.add(roll)\n",
    "    session.flush() # populates roll.id\n",
    "    vid = media['lowResVideoPath'].split('/')[-1].split('.')[0]\n",
    "    vid = f\"%videos%/{sensor.abbreviation}/{vid}.mp4\"\n",
    "    session.add(RollFile(roll_id=roll.id,\n",
    "                         sensor_id=sensor.id,\n",
    "                         type='video_preview',\n",
    "                         uri=vid))\n",
    "    \n",
    "    fit = media['fitURL'].split('/')[-1].split('.')[0]\n",
    "    fit = f\"%fit%/{sensor.abbreviation}/{fit}.fit\"\n",
    "    session.add(RollFile(roll_id=roll.id,\n",
    "                         sensor_id=sensor.id,\n",
    "                         type='fit',\n",
    "                         uri=fit))\n",
    "    if use_thm:\n",
    "        thm = media['thumbUrl'].split('/')[-1].split('.')[0]\n",
    "        thm = f\"%thumbnails%/{sensor.abbreviation}/{thm}.jpg\"\n",
    "        session.add(RollFile(roll_id=roll.id,\n",
    "                            sensor_id=sensor.id,\n",
    "                            type='thumbnail',\n",
    "                            uri=thm))\n",
    "        \n",
    "    return roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "with Session(engine) as session:\n",
    "    for file in file_list:\n",
    "        i = 0\n",
    "        media_list = media_lists[file]\n",
    "        match file:\n",
    "            case \"zr/medialist.json\":\n",
    "                roll_date = session.scalars(\n",
    "                    select(RollDate).where(\n",
    "                        RollDate.year == 2025, \n",
    "                        RollDate.month == 9, \n",
    "                        RollDate.day == 21\n",
    "                    ) \n",
    "                ).one() \n",
    "                \n",
    "                sensor = session.scalars(\n",
    "                    select(Sensor)\n",
    "                        .where(Sensor.abbreviation == \"zr\") \n",
    "                ).one()\n",
    "                driver = session.scalars(select(Driver)\n",
    "                                        .where(Driver.name == \"Mei Xi\")).one()\n",
    "                buggy = session.scalars(select(Buggy)\n",
    "                                        .where(Buggy.abbreviation == \"inviscid\")).one()\n",
    "                thm = False\n",
    "            case \"ir/medialist.json\":\n",
    "                roll_date = session.scalars(\n",
    "                    select(RollDate).where(\n",
    "                        RollDate.year == 2025,\n",
    "                        RollDate.month == 11, \n",
    "                        RollDate.day == 2\n",
    "                    ) \n",
    "                ).one() \n",
    "                \n",
    "                sensor = session.scalars(\n",
    "                    select(Sensor)\n",
    "                        .where(Sensor.abbreviation == \"ir\") \n",
    "                ).one()\n",
    "                driver = session.scalars(select(Driver)\n",
    "                                        .where(Driver.name == \"Cadence\")).one()\n",
    "                buggy = session.scalars(select(Buggy)\n",
    "                                        .where(Buggy.abbreviation == \"seraph\")).one()\n",
    "                thm = True\n",
    "    \n",
    "        for media in media_list:\n",
    "            r = add_roll(session, media, roll_date, driver, buggy, sensor, roll_nums[i % len(roll_nums)], thm)\n",
    "            print(r)\n",
    "            i += 1\n",
    "    # session.rollback()\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for roll in media_list:\n",
    "    vid = roll['lowResVideoPath'].split('/')[-1].split('.')[0]\n",
    "    vid = f\"videos/zuke_r/{vid}.GLV\"\n",
    "    # thum = roll['thumbUrl'].split('/')[-1].split('.')[0]\n",
    "    fit = roll['fitURL'].split('/')[-1].split('.')[0]\n",
    "    fit = f\"backend/notebooks/data/zr/{fit}.fit\"\n",
    "    print(vid, fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e38f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n",
    "    d = session.scalars(select(Driver)\n",
    "                        .where(Driver.name == \"Alani\")).one() \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with get_connection() as conn:\n",
    "#     conn.execute(insert(driver_table).values(name=\"Alani\"))\n",
    "#     conn.execute(insert(driver_table).values(name=\"Audrey\"))\n",
    "#     conn.execute(insert(driver_table).values(name=\"Cadence\"))\n",
    "#     conn.execute(insert(driver_table).values(name=\"Daisy\"))\n",
    "#     conn.execute(insert(driver_table).values(name=\"Mei Xi\"))\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with get_connection() as conn:\n",
    "#     result = conn.execute(driver_table.select())\n",
    "#     for row in result:\n",
    "#         print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
